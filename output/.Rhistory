batting_tbl <- copy_to(sc, Lahman::Batting, "batting")
src_tbls(sc)
flights_tbl %>% filter(dep_delay == 2)
delay <- flights_tbl %>%
group_by(tailnum) %>%
summarise(count = n(), dist = mean(distance), delay = mean(arr_delay)) %>%
filter(count > 20, dist < 2000, !is.na(delay)) %>%
collect
library(ggplot2)
ggplot(delay, aes(dist, delay)) +
geom_point(aes(size = count), alpha = 1/2) +
geom_smooth() +
scale_size_area(max_size = 2)
batting_tbl %>%
select(playerID, yearID, teamID, G, AB:H) %>%
arrange(playerID, yearID, teamID) %>%
group_by(playerID) %>%
filter(min_rank(desc(H)) <= 2 & H > 0)
# plot delays
library(ggplot2)
ggplot(delay, aes(dist, delay)) +
geom_point(aes(size = count), alpha = 1/2) +
geom_smooth() +
scale_size_area(max_size = 2)
library(DBI)
iris_preview <- dbGetQuery(sc, "SELECT * FROM iris LIMIT 10")
iris_preview
mtcars_tbl <- copy_to(sc, mtcars)
partitions <- mtcars_tbl %>%
filter(hp >= 100) %>%
mutate(cyl8 = cyl == 8) %>%
sdf_partition(training = 0.5, test = 0.5, seed = 1099)
fit <- partitions$training %>%
ml_linear_regression(response = "mpg", features = c("wt", "cyl"))
fit
summary(fit)
rf_model <- iris_tbl %>%
ml_random_forest(Species ~ Petal_Length + Petal_Width, type = "classification")
rf_predict <- sdf_predict(rf_model, iris_tbl) %>%
ft_string_indexer("Species", "Species_idx") %>%
collect
table(rf_predict$Species_idx, rf_predict$prediction)
partitions <- tbl(sc, "iris") %>%
sdf_partition(training = 0.75, test = 0.25, seed = 1099)
fit <- partitions$training %>%
ml_linear_regression(Petal_Length ~ Petal_Width)
estimate_mse <- function(df){
sdf_predict(fit, df) %>%
mutate(resid = Petal_Length - prediction) %>%
summarize(mse = mean(resid ^ 2)) %>%
collect
}
sapply(partitions, estimate_mse)
kmeans_model <- iris_tbl %>%
select(Petal_Width, Petal_Length) %>%
ml_kmeans(centers = 3)
print(kmeans_model)
predicted <- sdf_predict(kmeans_model, iris_tbl) %>%
collect
table(predicted$Species, predicted$prediction)
sdf_predict(kmeans_model) %>%
collect() %>%
ggplot(aes(Petal_Length, Petal_Width)) +
geom_point(aes(Petal_Width, Petal_Length, col = factor(prediction + 1)),
size = 2, alpha = 0.5) +
geom_point(data = kmeans_model$centers, aes(Petal_Width, Petal_Length),
col = scales::muted(c("red", "green", "blue")),
pch = 'x', size = 12) +
scale_color_discrete(name = "Predicted Cluster",
labels = paste("Cluster", 1:3)) +
labs(
x = "Petal Length",
y = "Petal Width",
title = "K-Means Clustering",
subtitle = "Use Spark.ML to predict cluster membership with the iris dataset."
)
lm_model <- iris_tbl %>%
select(Petal_Width, Petal_Length) %>%
ml_linear_regression(Petal_Length ~ Petal_Width)
iris_tbl %>%
select(Petal_Width, Petal_Length) %>%
collect %>%
ggplot(aes(Petal_Length, Petal_Width)) +
geom_point(aes(Petal_Width, Petal_Length), size = 2, alpha = 0.5) +
geom_abline(aes(slope = coef(lm_model)[["Petal_Width"]],
intercept = coef(lm_model)[["(Intercept)"]]),
color = "red") +
labs(
x = "Petal Width",
y = "Petal Length",
title = "Linear Regression: Petal Length ~ Petal Width",
subtitle = "Use Spark.ML linear regression to predict petal length as a function of petal width."
)
pca_model <- tbl(sc, "iris") %>%
select(-Species) %>%
ml_pca()
print(pca_model)
sets <- sparklyr::sdf_partition(iris, training=0.7, test = 0.3)
library(dplyr)
iris_tbl <- copy_to(sc, iris)
sets <- sparklyr::sdf_partition(iris_tbl, training=0.7, test = 0.3)
train <- sets$training
test <- sets$test
train
summary(train)
train
test
dt <- ml_decision_tree(train , "Species", c("Sepal_Length", "Sepal_Width"), max.bins = 200L, max.depth=10L, seed=123L)
dt <- ml_decision_tree(train , "Species", c("Sepal_Length", "Sepal_Width"), max.bins = 200L, max.depth=10L, seed=123L)
pca_model <- tbl(sc, "iris") %>%
select(-Species) %>%
ml_pca()
print(pca_model)
iris_tbl %>%
select(Petal_Width, Petal_Length) %>%
collect %>%
ggplot(aes(Petal_Length, Petal_Width)) +
geom_point(aes(Petal_Width, Petal_Length), size = 2, alpha = 0.5) +
geom_abline(aes(slope = coef(lm_model)[["Petal_Width"]],
intercept = coef(lm_model)[["(Intercept)"]]),
color = "red") +
labs(
x = "Petal Width",
y = "Petal Length",
title = "Linear Regression: Petal Length ~ Petal Width",
subtitle = "Use Spark.ML linear regression to predict petal length as a function of petal width."
)
sdf_predict(kmeans_model) %>%
collect() %>%
ggplot(aes(Petal_Length, Petal_Width)) +
geom_point(aes(Petal_Width, Petal_Length, col = factor(prediction + 1)),
size = 2, alpha = 0.5) +
geom_point(data = kmeans_model$centers, aes(Petal_Width, Petal_Length),
col = scales::muted(c("red", "green", "blue")),
pch = 'x', size = 12) +
scale_color_discrete(name = "Predicted Cluster",
labels = paste("Cluster", 1:3)) +
labs(
x = "Petal Length",
y = "Petal Width",
title = "K-Means Clustering",
subtitle = "Use Spark.ML to predict cluster membership with the iris dataset."
)
kmeans_model <- iris_tbl %>%
select(Petal_Width, Petal_Length) %>%
ml_kmeans(centers = 10)
print(kmeans_model)
predicted <- sdf_predict(kmeans_model, iris_tbl) %>%
collect
table(predicted$Species, predicted$prediction)
sdf_predict(kmeans_model) %>%
collect() %>%
ggplot(aes(Petal_Length, Petal_Width)) +
geom_point(aes(Petal_Width, Petal_Length, col = factor(prediction + 1)),
size = 2, alpha = 0.5) +
geom_point(data = kmeans_model$centers, aes(Petal_Width, Petal_Length),
col = scales::muted(c("red", "green", "blue")),
pch = 'x', size = 12) +
scale_color_discrete(name = "Predicted Cluster",
labels = paste("Cluster", 1:3)) +
labs(
x = "Petal Length",
y = "Petal Width",
title = "K-Means Clustering",
subtitle = "Use Spark.ML to predict cluster membership with the iris dataset."
)
kmeans_model <- iris_tbl %>%
select(Petal_Width, Petal_Length) %>%
ml_kmeans(centers = 2)
print(kmeans_model)
predicted <- sdf_predict(kmeans_model, iris_tbl) %>%
collect
table(predicted$Species, predicted$prediction)
sdf_predict(kmeans_model) %>%
collect() %>%
ggplot(aes(Petal_Length, Petal_Width)) +
geom_point(aes(Petal_Width, Petal_Length, col = factor(prediction + 1)),
size = 2, alpha = 0.5) +
geom_point(data = kmeans_model$centers, aes(Petal_Width, Petal_Length),
col = scales::muted(c("red", "green", "blue")),
pch = 'x', size = 12) +
scale_color_discrete(name = "Predicted Cluster",
labels = paste("Cluster", 1:3)) +
labs(
x = "Petal Length",
y = "Petal Width",
title = "K-Means Clustering",
subtitle = "Use Spark.ML to predict cluster membership with the iris dataset."
)
lm_model <- iris_tbl %>%
select(Petal_Width, Petal_Length) %>%
ml_linear_regression(Petal_Length ~ Petal_Width)
kmeans_model <- iris_tbl %>%
select(Petal_Width, Petal_Length) %>%
ml_kmeans(centers = 3)
print(kmeans_model)
predicted <- sdf_predict(kmeans_model, iris_tbl) %>%
collect
table(predicted$Species, predicted$prediction)
sdf_predict(kmeans_model) %>%
collect() %>%
ggplot(aes(Petal_Length, Petal_Width)) +
geom_point(aes(Petal_Width, Petal_Length, col = factor(prediction + 1)),
size = 2, alpha = 0.5) +
geom_point(data = kmeans_model$centers, aes(Petal_Width, Petal_Length),
col = scales::muted(c("red", "green", "blue")),
pch = 'x', size = 12) +
scale_color_discrete(name = "Predicted Cluster",
labels = paste("Cluster", 1:3)) +
labs(
x = "Petal Length",
y = "Petal Width",
title = "K-Means Clustering",
subtitle = "Use Spark.ML to predict cluster membership with the iris dataset."
)
library(sparklyr)
sc <- spark_connect(master = "local")
library(dplyr)
data("USArrests")
data("USArrests")
my_data <- USArrests
my_data <- na.omit(my_data)
my_data <- scale(my_data)
head(my_data, n = 3)
my_data
my_data_tbl <- copy_to(sc, my_data)
src_tbls(sc)
my_data_tbl <- copy_to(sc, my_data)
sets <- sparklyr::sdf_partition(my_data_tbl, training=0.7, test = 0.3)
train <- sets$training
test <- sets$test
train
test
sets <- sparklyr::sdf_partition(my_data_tbl, training=0.7, test = 0.3, seed = 1099)
train <- sets$training
test <- sets$test
sets <- sparklyr::sdf_partition(my_data_tbl, training=0.7, test = 0.3, seed = 1234)
train <- sets$training
test <- sets$test
train
test
sets <- sparklyr::sdf_partition(my_data_tbl, training=0.7, test = 0.3, seed = 1234)
train <- sets$training
test <- sets$test
train
test
kmeans_model <- train %>%
select(Murder, Assault, UrbanPop, Rape) %>%
ml_kmeans(centers = 5)
kmeans_model <- train %>%
select(!is.na(Murder), !is.na(Assault), !is.na(UrbanPop), !is.na(Rape)) %>%
ml_kmeans(centers = 5)
kmeans_model <- train %>%
#  select(!is.na(Murder), !is.na(Assault), !is.na(UrbanPop), !is.na(Rape)) %>%
select(Murder, Assault, UrbanPop, Rape) %>%
ml_kmeans(centers = 5)
print(kmeans_model)
predicted <- sdf_predict(kmeans_model, test) %>%
collect
table(predicted$Species, predicted$prediction)
predicted <- sdf_predict(kmeans_model, test) %>%
collect
table(predicted$Murder, predicted$prediction)
sdf_predict(kmeans_model) %>%
collect() %>%
ggplot(aes(Murder, Assault, UrbanPop, Rape)) +
geom_point(aes(Murder, Assault, UrbanPop, Rape, col = factor(prediction + 1)),
size = 2, alpha = 0.5) +
geom_point(data = kmeans_model$centers, aes(Murder, Assault, UrbanPop, Rape),
col = scales::muted(c("red", "green", "blue")),
pch = 'x', size = 12) +
scale_color_discrete(name = "Predicted Cluster",
labels = paste("Cluster", 1:5)) +
labs(
x = "Petal Length",
y = "Petal Width",
title = "K-Means Clustering",
subtitle = "Use Spark.ML to predict cluster membership with the iris dataset."
)
print(kmeans_model)
library("cluster")
library("factoextra")
install.packages("factoextra")
install.packages("factoextra")
install.packages("factoextra")
install.packages("factoextra")
library("cluster")
library("factoextra")
library("factoextra")
library("ggplot2")
install.packages("ggplot2")
library("ggplot2")
data("USArrests")
my_data <- scale(USArrests)
d <- dist(my_data, method = "euclidean")
res.hc <- hclust(d, method = "ward.D2" )
grp <- cutree(res.hc, k = 4)
plot(res.hc, cex = 0.6) # plot tree
rect.hclust(res.hc, k = 4, border = 2:5) # add rectangle
data("USArrests")
my_data <- scale(USArrests)
d <- dist(my_data, method = "euclidean")
res.hc <- hclust(d, method = "ward.D2" )
grp <- cutree(res.hc, k = 10)
plot(res.hc, cex = 0.6) # plot tree
plot(res.hc, cex = 0.6) # plot tree
rect.hclust(res.hc, k = 10, border = 2:5) # add rectangle
data("USArrests")
my_data <- scale(USArrests)
d <- dist(my_data, method = "euclidean")
res.hc <- hclust(d, method = "ward.D2" )
grp <- cutree(res.hc, k = 15)
plot(res.hc, cex = 0.6) # plot tree
rect.hclust(res.hc, k = 15, border = 2:5) # add rectangle
data("USArrests")
my_data <- scale(USArrests)
k_number = 15
d <- dist(my_data, method = "euclidean")
res.hc <- hclust(d, method = "ward.D2" )
grp <- cutree(res.hc, k = k_number)
plot(res.hc, cex = 0.6) # plot tree
rect.hclust(res.hc, k = k_number, border = 2:5) # add rectangle
# 1. Loading and preparing data
data("USArrests")
my_data <- scale(USArrests)
# Cluster number
k_number = 3
# 2. Compute dissimilarity matrix
d <- dist(my_data, method = "euclidean")
# Hierarchical clustering using Ward's method
res.hc <- hclust(d, method = "ward.D2" )
# Cut tree into 4 groups
grp <- cutree(res.hc, k = k_number)
# Visualize
plot(res.hc, cex = 0.6) # plot tree
rect.hclust(res.hc, k = k_number, border = 2:5) # add rectangle
install.packages("factoextra")
install.packages("cluster")
install.packages("cluster")
install.packages("ggplot2")
library("cluster")
library("factoextra")
library("ggplot2")
data("USArrests")
my_data <- scale(USArrests)
d <- dist(my_data, method = "euclidean")
res.hc <- hclust(d, method = "ward.D2" )
grp <- cutree(res.hc, k = 4)
plot(res.hc, cex = 0.6) # plot tree
rect.hclust(res.hc, k = 4, border = 2:5) # add rectangle
data("USArrests")
my_data <- scale(USArrests)
k_number = 3
d <- dist(my_data, method = "euclidean")
res.hc <- hclust(d, method = "ward.D2" )
grp <- cutree(res.hc, k = k_number)
plot(res.hc, cex = 0.6) # plot tree
rect.hclust(res.hc, k = k_number, border = 2:5) # add rectangle
library(sparklyr)
spark_install(logging = "INFO", verbose = interactive())
sc <- spark_connect(master = "local")
library(dplyr)
iris_tbl <- copy_to(sc, iris)
flights_tbl <- copy_to(sc, nycflights13::flights, "flights")
batting_tbl <- copy_to(sc, Lahman::Batting, "batting")
src_tbls(sc)
flights_tbl %>% filter(dep_delay == 2)
delay <- flights_tbl %>%
group_by(tailnum) %>%
summarise(count = n(), dist = mean(distance), delay = mean(arr_delay)) %>%
filter(count > 20, dist < 2000, !is.na(delay)) %>%
collect
library(ggplot2)
ggplot(delay, aes(dist, delay)) +
geom_point(aes(size = count), alpha = 1/2) +
geom_smooth() +
scale_size_area(max_size = 2)
rf_model <- iris_tbl %>%
ml_random_forest(Species ~ Petal_Length + Petal_Width, type = "classification")
rf_predict <- sdf_predict(rf_model, iris_tbl) %>%
ft_string_indexer("Species", "Species_idx") %>%
collect
table(rf_predict$Species_idx, rf_predict$prediction)
partitions <- tbl(sc, "iris") %>%
sdf_partition(training = 0.75, test = 0.25, seed = 1099)
fit <- partitions$training %>%
ml_linear_regression(Petal_Length ~ Petal_Width)
estimate_mse <- function(df){
sdf_predict(fit, df) %>%
mutate(resid = Petal_Length - prediction) %>%
summarize(mse = mean(resid ^ 2)) %>%
collect
}
sapply(partitions, estimate_mse)
function(x) {
salary = rent_value / 0.3
salary
}
x(1000)
function salary(x) {
salary = rent_value / 0.3
salary
}
salary <- function (x) {
salary = rent_value / 0.3
salary
}
salary(1000)
salary <- function (x) {
rent_value = x
salary = rent_value / 0.3
salary
}
rent_value
salary <- function (x) {
rent_value = x
salary = rent_value / 0.3
salary
}
rent_value = 1000
mysalary <- salary(rent_value)
salary <- function (x) {
rent_value = x
salary = rent_value / 0.3
return(salary)
}
rent_value = 1000
1+1
salary <- function (x) {
rent_value = x
salary = rent_value / 0.3
return(salary)
}
x = 1000
mysalary <- salary(x)
mysalary
salary <- function (x) {
rent_value = x
salary = rent_value / 0.3
return(salary)
}
x = 500
mysalary <- salary(x)
mysalary
AirPassengers;
tsPassageiros<-ts(AirPassengers, start=1949, end=1959, frequency=12);
tsPassageiros;
plot(tsPassageiros, col=20);
hw<-HoltWinters(tsPassageiros);
hw;
predicao<-predict(hw,n.ahead=24);
predicao;
AirPassengers;
predicao;
predicao<-predict(hw,n.ahead=3);
predicao3m<-predict(hw,n.ahead=3);
predicao3m;
predicao24m<-predict(hw,n.ahead=24);
predicao24m
predicao36m<-predict(hw,n.ahead=36);
predicao36m;
lines(predicao36m);
correlacao <- corr();
correlacao <- corr();
correlacao <- corr();
library(corrplot)
M <- cor(mtcars)
corrplot(M, method="circle")
library(corrplot)
M <- cor(AirPassengers)
corrplot(M, method="circle")
library(corrplot)
M <- cor(mtcars)
corrplot(M, method="circle")
library(corrplot)
M <- cor(mtcars)
corrplot(M, method="circle")
corrplot(M, method="number")
corrplot(M, type="upper")
corrplot(M, method="circle")
corrplot(M, method="number")
corrplot(M, type="upper")
corrplot(M, order ="hclust")
out <- capture.output(summary(output_result))
M <- cor(mtcars)
M
out <- capture.output(M)
cat("My title", out, file="output_result.txt", sep="n", append=TRUE)
cat("", out, file="output_result.txt", sep="n", append=TRUE)
cat("", out, file="output_result.txt", sep="n", append=TRUE)
out <- capture.output(M)
cat("", out, file="output_result.txt", sep="n", append=TRUE)
library(corrplot)
M <- cor(mtcars)
M
out <- capture.output(M)
cat("", out, file="output_result.txt", sep="n", append=TRUE)
setwd("~/git/github.com/minerva-auto-mining/output")
library(corrplot)
M <- cor(mtcars)
setwd("~/git/github.com/minerva-auto-mining/output")
out <- capture.output(M)
cat("", out, file="output_r_result.txt", sep="n", append=TRUE)
data(airquality)
names(airquality)
plot(Ozone~Solar.R,data=airquality)
mean.Ozone=mean(airquality$Ozone,na.rm=T)
abline(h=mean.Ozone)
model1=lm(Ozone~Solar.R,data=airquality)
model1
abline(model1,col="red")
plot(model1)
